{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"xm - regression clv case.ipynb","provenance":[{"file_id":"1VV69cNgyrCKMFoYU-2FlsWfym4pNTKia","timestamp":1593758267222},{"file_id":"142ZshJV0wFuTxZH9Savi-JJfWdCWF_AN","timestamp":1593707691738}],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Yd3FdfgRfDhr"},"source":["# Customer Lifetime Value and Boston House Price"]},{"cell_type":"markdown","metadata":{"id":"cNkFLcDQmugY","colab_type":"text"},"source":["- <font size=3>https://reurl.cc/8Gagoy</font>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tkX-uqMQggLa"},"source":["# 載入程式庫及必要定義"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nZaLIy7QfBIU","colab":{}},"source":["try:\n","    from google.colab import drive, files\n","    in_colab = True\n","except ModuleNotFoundError:\n","    in_colab = False\n","\n","if in_colab:\n","    home_dir = ''\n","    drive.mount('/content/drive')\n","    groot_dir = '/content/drive/My Drive/adventures/'\n","else:\n","    from pathlib import Path\n","    home_dir = str(Path.home())\n","    groot_dir = home_dir + '/Google Drive/adventures/'\n","\n","import matplotlib as mpl\n","mpl.rc('axes', labelsize=14)\n","mpl.rc('xtick', labelsize=14)\n","mpl.rc('ytick', labelsize=14)\n","mpl.rc('font', size=14)\n","\n","from datetime import datetime\n","from dateutil.relativedelta import *\n","import matplotlib.pyplot as plt\n","import sklearn\n","assert sklearn.__version__ >= \"0.20\"\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","import math\n","import os\n","import sys\n","import gdown\n","import requests\n","# Ignore useless warnings (see SciPy issue #5998)\n","import warnings\n","warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n","from pandas.plotting import register_matplotlib_converters\n","\n","figure_dir = groot_dir + 'figure/regression/'\n","data_dir = groot_dir + 'regression/'\n","\n","gfigure = lambda name: figure_dir + name + '.png'\n","output_fig = lambda name: plt.savefig( gfigure(name), dpi = 300)\n","\n","local_time = lambda x, offset: x + relativedelta(hours= offset)\n","def local_now(hours = 8):\n","    return datetime.now() + relativedelta(hours = hours if in_colab else 0)\n","\n","def print_now():\n","    return print(local_now())\n","\n","def print_local_now():\n","    return print('Local Time:', local_now())\n","\n","def DropboxLink(did, fname):\n","    return 'https://dl.dropboxusercontent.com/s/%s/%s' % \\\n","    (did, fname)\n","\n","def fetch_gdrive_file(fid, local_save):\n","    remote_url = 'https://drive.google.com/uc?id=' + fid\n","    gdown.download(remote_url, local_save, quiet = False)\n","\n","def fetch_file_via_requests(url, save_in_dir):\n","    local_filename = url.split('/')[-1]\n","    # NOTE the stream=True parameter below\n","    output_fpath = save_in_dir + local_filename\n","    with requests.get(url, stream=True) as r:\n","        r.raise_for_status()\n","        with open(output_fpath, 'wb') as f:\n","            for chunk in r.iter_content(chunk_size=8192): \n","                if chunk: # filter out keep-alive new chunks\n","                    f.write(chunk)\n","                    # f.flush()\n","    return output_fpath\n","        \n","def acct_string(num):\n","    s0 = str(num)\n","    if len(s0) <=3:\n","        return s0  \n","    num_section = int(len(s0)/3)\n","    remaining_start = len(s0) % 3\n","    s = s0[:remaining_start]\n","    for i in range(num_section):\n","        s += ',%s' % s0[remaining_start + i*3 :remaining_start + (i+1)*3]   \n","    return s\n","\n","def round_up(n, decimals=0):\n","    multiplier = 10 ** decimals\n","    return math.ceil(n * multiplier) / multiplier\n","\n","def round_down(n, decimals=0):\n","    multiplier = 10 ** decimals\n","    return math.floor(n * multiplier) / multiplier\n","\n","def start_plot(figsize=(10, 8), style = 'whitegrid'):\n","    fig = plt.figure(figsize=figsize)\n","    gs = fig.add_gridspec(1,1)\n","    plt.tight_layout()\n","    with sns.axes_style(style):\n","        ax = fig.add_subplot(gs[0,0])\n","    return ax\n","\n","EX1DATA = '147xBeCECYur0FxDyly-oG2BqsqEH2Mxm'\n","EX1DATA2 = '101qw-9OkjCxwuSkBJUBaGURRWpZbFKOe'\n","EX5DATA = '1nNM8CN9CkRfjipRx1qJYZhSobmABVL1J'\n","ADVER = '1xFMcCuiMgX9VnelDtbyyV9rXBMFerx8k'\n","TAIWAN_CSV = '1I5yqulrZSHPSQkxT3oqt_3uVAhPolOEP'\n","JHU_CSSE = 'https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/'\n","MNIST_TRAIN = '1E-uJ0zqqAfpsVjoOSzqF5TXhDfPNlkQ5'\n","MNIST_TRAIN_LABEL = '13clNJ2cd2I90W3DEkDBKjZSDNNEqqx3B'\n","MNIST_TEST = '1zVpVHJl5YABa3qExt1K-O3WaEHXTJekg'\n","MNIST_TEST_LABEL = '1qci_-dqubnRN-cdrCsbYaUAxyO7_jH9z'\n","\n","print('\\nRunning on %s' % sys.platform)\n","print('Python Version', sys.version)\n","print('Data storage points to ==>', data_dir)\n","\n","print('\\nThis module is amied to leran regression basics...') \n","print('\\nLibraries and dependenciess imported')\n","print_now()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1qN8uR68q3L_","colab_type":"text"},"source":["dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tX9cRKDSgnco"},"source":["# 下載資料檔案"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qnHtB4KnfPyj","colab":{}},"source":["fetch_file_via_requests(\n","    DropboxLink('e7lsf1k6258w7co', 'ec_201012_test_4.csv'), data_dir )\n","\n","fetch_file_via_requests(\n","    DropboxLink('fwokyefy0looizp', 'ec_201012_train_4.csv'), data_dir )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gZ3g87efqvap","colab_type":"code","colab":{}},"source":["import sklearn.metrics\n","for x in sklearn.metrics.SCORERS.keys():\n","    print(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gO7SN2TGg1SP"},"source":["# Preparing Data\n","\n","訓練資料與測試（test）資料的名稱 ec_201012_train_4.csv 和 ec_201012_test_4.csv, 這兩個資料集的欄位相同，包括：\n","\n","```\n","'CustomerID', 'date_size', 'date_recency', 'date_time_between',\n","'date_T', 'baseket_value_sum', 'baseket_value_mean',\n","'baseket_value_std', 'baseket_value_amax', 'baseket_value_amin',\n","'baseket_value_median', 'basket_size_sum', 'basket_size_mean',\n","'basket_size_std', 'basket_size_amax', 'basket_size_amin',\n","'basket_size_median', 'lag_12', 'lag_11', 'lag_10', 'lag_9', 'lag_8',\n","'lag_7', 'lag_6', 'lag_5', 'lag_4', 'lag_3', 'lag_2', 'lag_1', 'value'\n","```\n","\n","最後一個欄位 <font color='brown'>‘value’</font> 是本案例需要預測的對象，是指未來一定期間內客戶購買的金額，也就是所謂的「貢獻值」。"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"K2VP7Rva98Jr"},"source":["### 資料命名規則"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LD2VZX_c9D25"},"source":["- CLV Case\n","    - train: 訓練集載入 DataFrame\n","    - test: 測試集載入 DataFrame\n","    - X_train, y_train (clv case 訓練集)\n","    - X_test, y_test (clv case 測試集)\n","- load_boston()\n","    - X_bos, y_bos (load_boston() 資料)\n","    - bos (資料打包為 Pandas DataFrame)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lSDJEjVqI2q9","colab":{}},"source":["train_csv = os.path.join(data_dir, 'ec_201012_train_4.csv')\n","test_csv = os.path.join(data_dir, 'ec_201012_test_4.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6iOBNLbkbnUN","colab":{}},"source":["train = pd.read_csv(train_csv)\n","test = pd.read_csv(test_csv)\n","\n","X_train = train.drop(['CustomerID','value'], axis = 1)\n","y_train = train.value\n","X_test = test.drop(['CustomerID','value'], axis = 1)\n","y_test = test.value"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0_ZXszemb4Lo","colab":{}},"source":["from sklearn.datasets import load_boston\n","\n","data = load_boston()\n","bos = pd.DataFrame(data = data['data'], \n","    columns = data['feature_names'])\n","bos['y'] = data['target']\n","X_bos = bos.drop(['y'], axis = 1)\n","y_bos = bos.y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C1eTh-RTR2Vq","colab_type":"text"},"source":["- CRIM per capita crime rate by town\n","\n","- ZN proportion of residential land zoned for lots over 25,000 sq.ft.\n","\n","- INDUS proportion of non-retail business acres per town\n","\n","- CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n","\n","- NOX nitric oxides concentration (parts per 10 million)\n","\n","- RM average number of rooms per dwelling\n","\n","- AGE proportion of owner-occupied units built prior to 1940\n","\n","- DIS weighted distances to five Boston employment centres\n","\n","- RAD index of accessibility to radial highways\n","\n","- TAX full-value property-tax rate per $10,000\n","\n","- PTRATIO pupil-teacher ratio by town\n","\n","- B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n","\n","- LSTAT % lower status of the population\n","\n","- MEDV Median value of owner-occupied homes in $1000’s"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zZvl066tVOmG"},"source":["## 常常需要載入的 Classes"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UdzGtTXyhJSZ","colab":{}},"source":["import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","\n","def simple_ols(xvec, yvec):\n","    Xadd = sm.add_constant(xvec)\n","    model = sm.OLS(yvec, Xadd).fit()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SndRnJxYldI8","colab":{}},"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.pipeline import Pipeline, make_pipeline\n","from sklearn.metrics import r2_score, mean_squared_error\n","from sklearn.model_selection import train_test_split, cross_val_score\n","import statsmodels.api as sm\n","import statsmodels.formula.api as smf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zg9dO7Keu3Jh"},"source":["# Modeling"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"F_rALEp7c4tu"},"source":["## Customter Lifetime Value"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cB_2LTHwnWej"},"source":["## load_boston"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qZxOBClj-aTB"},"source":["# Charting"]},{"cell_type":"code","metadata":{"id":"43HmKubnB7CS","colab_type":"code","colab":{}},"source":["def start_plot(figsize=(10, 8), style = 'whitegrid'):\n","    fig = plt.figure(figsize=figsize)\n","    gs = fig.add_gridspec(1,1)\n","    plt.tight_layout()\n","    with sns.axes_style(style):\n","        ax = fig.add_subplot(gs[0,0])\n","    return ax"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gNUxiURdustX"},"source":["## 誤差值的統計分佈模型 Distribution of Residuals"]},{"cell_type":"markdown","metadata":{"id":"DW1tQqGlOw_w","colab_type":"text"},"source":["- Points are **independent** of each other (residuals are uncorrelated)\n","- <font color='brown'>**residual ε are normally distributed with  μ = 0**</font>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cWxchr24ngMa"},"source":["## 預測值的範圍與分佈"]},{"cell_type":"markdown","metadata":{"id":"RYb4ZR_KJlDi","colab_type":"text"},"source":["## $ y  - \\hat y$ (預測效果) 的分析 （Regression Prediction Error）\n","\n","- [YellowBrick PredictionErrorPlot](https://www.scikit-yb.org/en/latest/api/regressor/peplot.html)\n","\n","![texto alternativo](https://www.scikit-yb.org/en/latest/api/regressor/peplot-1.png)"]},{"cell_type":"code","metadata":{"id":"sSqRzk4HuhHL","colab_type":"code","colab":{}},"source":["!pip3 install --upgrade yellowbrick"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XFG9S7ZlUyPX","colab_type":"text"},"source":["## Residuals Analysis 錯誤值的分析"]},{"cell_type":"markdown","metadata":{"id":"Gr4U-cDjk8lv","colab_type":"text"},"source":["- [Residuals Plot](https://www.scikit-yb.org/en/latest/api/regressor/residuals.html)"]},{"cell_type":"markdown","metadata":{"id":"XfF85aWukynl","colab_type":"text"},"source":["### My Residuals Plot"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gqJZREijuyCk"},"source":["## 學習曲線"]},{"cell_type":"code","metadata":{"id":"HIbs4EpTlmZ_","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import learning_curve\n","\n","#\n","# Simplified version of plot_learning_curves presented in \n","#   https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n","#\n","\n","def my_plot_leaning_curves(model, X, y, cv=None, scoring = None,\n","        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 10)):\n","    \n","       \n","    fig,ax = plt.subplots(figsize = (10, 8))\n","    ax.set_xlabel(\"Training examples\")\n","    ax.set_ylabel(\"Score\")\n","\n","    train_sizes, train_scores, test_scores, fit_times, _ = \\\n","        learning_curve(model, X, y, cv=cv, n_jobs=n_jobs, \n","            scoring = scoring,\n","            train_sizes=train_sizes,\n","            return_times=True)\n","    train_scores_mean = np.mean(train_scores, axis=1)\n","    train_scores_std = np.std(train_scores, axis=1)\n","    test_scores_mean = np.mean(test_scores, axis=1)\n","    test_scores_std = np.std(test_scores, axis=1)\n","    fit_times_mean = np.mean(fit_times, axis=1)\n","    fit_times_std = np.std(fit_times, axis=1)\n","\n","    # Plot learning curve\n","\n","\n","    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n","                 label=\"Training score\")\n","    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n","                 label=\"Cross-validation score\")\n","    ax.grid(b = 'on', ls = '--', alpha = 0.8)\n","    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n","                         train_scores_mean + train_scores_std, alpha=0.1,\n","                         color=\"r\")\n","    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n","                         test_scores_mean + test_scores_std, alpha=0.1,\n","                         color=\"g\")\n","\n","    ax.legend(loc=\"best\", fontsize = 14, shadow =True, frameon = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nV4yxqZAlt_y","colab_type":"code","colab":{}},"source":["my_plot_leaning_curves(LinearRegression(), X_bos, y_bos,\n","    train_sizes=np.linspace(.1, 1.0, 5),\n","    scoring='neg_root_mean_squared_error')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4u93ZiaE-g2R"},"source":["# Metrics & Outliers"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1oAAhSNYbqUM"},"source":["## Cook's Distance"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XbU3h--uksU8"},"source":["- [Wikipedia](https://en.wikipedia.org/wiki/Cook%27s_distance)\n","- [Mathworks](https://www.mathworks.com/help/stats/cooks-distance.html#:~:text=Cook's%20distance%20is%20the%20scaled,on%20the%20fitted%20response%20values.)\n","- [Stackoverflow QA](https://stackoverflow.com/questions/51390196/how-to-calculate-cooks-distance-dffits-using-python-statsmodel)\n","\n","- [MAPE formula](https://stats.stackexchange.com/questions/58391/mean-absolute-percentage-error-mape-in-scikit-learn/294069#294069)\n","\n","- [Issue 15007](https://github.com/scikit-learn/scikit-learn/pull/15007)\n","\n",">Simply said, Cook’s D is calculated by removing the ith data point from the model and recalculating the regression. All the values in the regression model are then observed whether changes have been detected after the removal of the point. This is an iterative way of examining the influence of that observation.\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AQz9eK2lnsqg"},"source":["以 loas_boston 為例：\n","\n","```\n","model = simple_ols(X_bos, y_bos)\n","infl = model.get_influence()\n","rdf = infl.summary_frame()\n","cooks_d = rdf['cooks_d']\n","```"]},{"cell_type":"markdown","metadata":{"id":"wqkrcuPGBLBz","colab_type":"text"},"source":["- [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n","- [What Is R Squared And Negative R Squared](http://www.fairlynerdy.com/what-is-r-squared/)\n","- [Can the multiple linear correlation coefficient be negative?](https://stats.stackexchange.com/questions/6181/can-the-multiple-linear-correlation-coefficient-be-negative)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7nl90yxICT1c"},"source":["### yellowbrick 版本"]},{"cell_type":"markdown","metadata":{"id":"Sk6Z3-f2BALK","colab_type":"text"},"source":["```\n","from yellowbrick.regressor import CooksDistance\n","from sklearn.datasets import load_boston\n","\n","data = load_boston()\n","X, y = data['data'], data['target']\n","\n","# Instantiate and fit the visualizer\n","visualizer = CooksDistance()\n","visualizer.fit(X, y)\n","visualizer.show()\n","```"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5Gx3H-m0Hv1x"},"source":["## VIF\n","\n",">Variance Inflation Factor (VIF) is used to detect the presence of multicollinearity. Variance inflation factors (VIF) measure how much the variance of the estimated regression coefficients are inflated as compared to when the predictor variables are not linearly related."]},{"cell_type":"markdown","metadata":{"id":"MCIkkgduuLiI","colab_type":"text"},"source":["- [select_dtypes](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.select_dtypes.html)\n","- [endog, exog, what’s that?](https://www.statsmodels.org/stable/endog_exog.html)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8Iv0UEL-H3eD","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","from patsy import dmatrices\n","import statsmodels.api as sm\n","from statsmodels.stats.outliers_influence import variance_inflation_factor\n","from sklearn.datasets import load_boston\n","\n","def vif_scores(df):\n","    df.dropna()\n","    # df = df._get_numeric_data()\n","    df = df.select_dtypes(include=[np.number])\n","    vif = pd.DataFrame()\n","\n","    vif[\"VIF Factor\"] = \\\n","        [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n","\n","    vif[\"features\"] = df.columns\n","    return vif\n","\n","def my_mape(estimator, X, y): \n","    estimator.fit(X, y)\n","    y_pred = estimator.predict(X)\n","    y_true = y\n","    y_true, y_pred = np.array(y_true), np.array(y_pred)\n","    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ed8tRjZ2-kub"},"source":["# 降維"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"69J1YM2la32t"},"source":["## Principal Component Analysis\n","\n","\n","- [線代啟示錄：主成分分析](https://ccjou.wordpress.com/2013/04/15/主成分分析/)\n","- [機器/統計學習:主成分分析(Principal Component Analysis, PCA)](https://medium.com/@chih.sheng.huang821/機器-統計學習-主成分分析-principle-component-analysis-pca-58229cd26e71)\n","- [主成分分析的原理](http://web.ntpu.edu.tw/~ccw/statmath/M_pca.pdf)\n","- [如何通俗易懂地讲解什么是 PCA 主成分分析？](https://www.zhihu.com/question/41120789)\n","- [scikit-learn PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)\n","- [scikit-learn User Guide: 2.5. Decomposing signals in components (matrix factorization problems)](https://scikit-learn.org/stable/modules/decomposition.html#pca)\n","\n","- [Principal Component Analysis (PCA) in Python](https://www.datacamp.com/community/tutorials/principal-component-analysis-in-python)\n","- [Feature Selection Techniques in Machine Learning with Python](https://towardsdatascience.com/feature-selection-techniques-in-machine-learning-with-python-f24e7da3f36e)\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZIrbrBv5TyVZ","colab":{}},"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import r2_score, mean_squared_error\n","\n","# model = LinearRegression()\n","\n","model = make_pipeline(\n","    StandardScaler(),\n","    LinearRegression()\n",")\n","\n","model.fit(X_train, y_train)\n","\n","yhat_train = model.predict(X_train)\n","yhat_test = model.predict(X_test)\n","\n","TRAINING_RMSE = -np.sqrt(mean_squared_error(y_train, yhat_train))\n","TEST_RMSE = -np.sqrt(mean_squared_error(y_test, yhat_test))\n","\n","TRAINING_SCORE = model.score(X_train, y_train)\n","TEST_SCORE = model.score(X_test, y_test)\n","\n","print('training: score = %.4f, neg rmse = %.4f' % \n","      (TRAINING_SCORE, TRAINING_RMSE))\n","# yhat = lin.predict(X_test)\n","print('test: score = %.4f, neg rmse = %.4f' % \n","      (TEST_SCORE, TEST_RMSE))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XVwPfNEOC_KL","colab_type":"code","colab":{}},"source":["from sklearn.decomposition import PCA\n","from sklearn.pipeline import Pipeline, make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import r2_score, mean_squared_error\n","from sklearn.linear_model import LinearRegression\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MkpuI2AGLTrC","colab_type":"text"},"source":["### Git it a try"]},{"cell_type":"code","metadata":{"id":"yGe8gDUFLWp1","colab_type":"code","colab":{}},"source":["from sklearn.pipeline import Pipeline\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.linear_model import LinearRegression\n","from sklearn.pipeline import Pipeline, make_pipeline\n","\n","def PCA_analysis(estimater, n_features, X_train, y_train, \n","    X_test = None, y_test = None):\n","\n","    N = n_features\n","\n","    scores_train = np.zeros(N)\n","    scores_test = np.zeros(N)\n","\n","    for i in np.arange(N, 2, -1):\n","        model = make_pipeline(\n","            PCA(n_components = i),\n","            estimater\n","        )\n","        model.fit(X_train, y_train)\n","        scores_train[i-1] = model.score(X_train, y_train)\n","        if X_test is not None:\n","            scores_test[i-1] = model.score(X_test, y_test)\n","\n","    xdomain = np.arange(2, N, 1)\n","    ax = start_plot(figsize=(10,7))\n","    ax.plot(xdomain, scores_train[2:], label = 'Training Scores')\n","    if X_test is not None:\n","        ax.plot(xdomain, scores_test[2:], color = 'brown',\n","            label = 'Test Scores')\n","    ax.legend(loc='lower center', frameon=True,shadow=True,fancybox=True,fontsize=14)\n"],"execution_count":null,"outputs":[]}]}